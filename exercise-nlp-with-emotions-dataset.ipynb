{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01967,
     "end_time": "2020-10-26T15:14:03.799231",
     "exception": false,
     "start_time": "2020-10-26T15:14:03.779561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Hello people, welcome to this kernel. In this kernel I am going to classify emotions using their texts. This kernel will be short as much as it can, so you can examine everything in a short time. Let's start.\n",
    "\n",
    "# Notebook Content\n",
    "1. Importing Libraries and The Data\n",
    "1. Preparing The Dataset\n",
    "    * Splitting X and Y\n",
    "    * Converting Y To Integer\n",
    "1. Tokenization\n",
    "    * Tokenizing\n",
    "    * Padding\n",
    "1. Modeling and Predicting\n",
    "1. Conclusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:03.842994Z",
     "iopub.status.busy": "2020-10-26T15:14:03.842147Z",
     "iopub.status.idle": "2020-10-26T15:14:03.856290Z",
     "shell.execute_reply": "2020-10-26T15:14:03.855760Z"
    },
    "papermill": {
     "duration": 0.038317,
     "end_time": "2020-10-26T15:14:03.856434",
     "exception": false,
     "start_time": "2020-10-26T15:14:03.818117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emotions-dataset-for-nlp/test.txt\n",
      "/kaggle/input/emotions-dataset-for-nlp/train.txt\n",
      "/kaggle/input/emotions-dataset-for-nlp/val.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:03.904301Z",
     "iopub.status.busy": "2020-10-26T15:14:03.903589Z",
     "iopub.status.idle": "2020-10-26T15:14:04.012858Z",
     "shell.execute_reply": "2020-10-26T15:14:04.012167Z"
    },
    "papermill": {
     "duration": 0.135407,
     "end_time": "2020-10-26T15:14:04.013014",
     "exception": false,
     "start_time": "2020-10-26T15:14:03.877607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/test.txt',sep=\";\",header=None)\n",
    "train = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/train.txt',sep=\";\",header=None)\n",
    "val = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/val.txt',sep=\";\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.066126Z",
     "iopub.status.busy": "2020-10-26T15:14:04.065180Z",
     "iopub.status.idle": "2020-10-26T15:14:04.073609Z",
     "shell.execute_reply": "2020-10-26T15:14:04.073047Z"
    },
    "papermill": {
     "duration": 0.040804,
     "end_time": "2020-10-26T15:14:04.073726",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.032922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.125629Z",
     "iopub.status.busy": "2020-10-26T15:14:04.124732Z",
     "iopub.status.idle": "2020-10-26T15:14:04.128392Z",
     "shell.execute_reply": "2020-10-26T15:14:04.128952Z"
    },
    "papermill": {
     "duration": 0.034345,
     "end_time": "2020-10-26T15:14:04.129069",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.094724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  im feeling rather rotten so im not very ambiti...  sadness\n",
       "1          im updating my blog because i feel shitty  sadness\n",
       "2  i never make her separate from me because i do...  sadness\n",
       "3  i left with my bouquet of red and yellow tulip...      joy\n",
       "4    i was feeling a little vain when i did this one  sadness"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.180938Z",
     "iopub.status.busy": "2020-10-26T15:14:04.179894Z",
     "iopub.status.idle": "2020-10-26T15:14:04.183874Z",
     "shell.execute_reply": "2020-10-26T15:14:04.184435Z"
    },
    "papermill": {
     "duration": 0.034284,
     "end_time": "2020-10-26T15:14:04.184560",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.150276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  im feeling quite sad and sorry for myself but ...  sadness\n",
       "1  i feel like i am still looking at a blank canv...  sadness\n",
       "2                     i feel like a faithful servant     love\n",
       "3                  i am just feeling cranky and blue    anger\n",
       "4  i can have for a treat or if i am feeling festive      joy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.246037Z",
     "iopub.status.busy": "2020-10-26T15:14:04.245371Z",
     "iopub.status.idle": "2020-10-26T15:14:04.249166Z",
     "shell.execute_reply": "2020-10-26T15:14:04.249818Z"
    },
    "papermill": {
     "duration": 0.043565,
     "end_time": "2020-10-26T15:14:04.249970",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.206405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       16000 non-null  object\n",
      " 1   1       16000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.303376Z",
     "iopub.status.busy": "2020-10-26T15:14:04.302563Z",
     "iopub.status.idle": "2020-10-26T15:14:04.306767Z",
     "shell.execute_reply": "2020-10-26T15:14:04.307251Z"
    },
    "papermill": {
     "duration": 0.035795,
     "end_time": "2020-10-26T15:14:04.307400",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.271605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       2000 non-null   object\n",
      " 1   1       2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.361878Z",
     "iopub.status.busy": "2020-10-26T15:14:04.361051Z",
     "iopub.status.idle": "2020-10-26T15:14:04.364688Z",
     "shell.execute_reply": "2020-10-26T15:14:04.365259Z"
    },
    "papermill": {
     "duration": 0.035452,
     "end_time": "2020-10-26T15:14:04.365390",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.329938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       2000 non-null   object\n",
      " 1   1       2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022862,
     "end_time": "2020-10-26T15:14:04.409920",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.387058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.469360Z",
     "iopub.status.busy": "2020-10-26T15:14:04.468384Z",
     "iopub.status.idle": "2020-10-26T15:14:04.474459Z",
     "shell.execute_reply": "2020-10-26T15:14:04.473722Z"
    },
    "papermill": {
     "duration": 0.041376,
     "end_time": "2020-10-26T15:14:04.474593",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.433217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000,) | (16000,)\n",
      "(2000,) | (2000,)\n",
      "(2000,) | (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting X and Y\n",
    "x_train = train.iloc[:,0] \n",
    "y_train = train.iloc[:,1] \n",
    "\n",
    "x_test = test.iloc[:,0] \n",
    "y_test = test.iloc[:,1] \n",
    "\n",
    "x_val = test.iloc[:,0] \n",
    "y_val = test.iloc[:,1] \n",
    "\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_test,y_test = np.array(x_test),np.array(y_test)\n",
    "x_val,y_val = np.array(x_val),np.array(y_val)\n",
    "\n",
    "print(x_train.shape,\"|\",y_train.shape)\n",
    "print(x_test.shape,\"|\",y_test.shape)\n",
    "print(x_val.shape,\"|\",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024974,
     "end_time": "2020-10-26T15:14:04.523656",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.498682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Now I will convert y to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:04.611058Z",
     "iopub.status.busy": "2020-10-26T15:14:04.605951Z",
     "iopub.status.idle": "2020-10-26T15:14:10.814528Z",
     "shell.execute_reply": "2020-10-26T15:14:10.813840Z"
    },
    "papermill": {
     "duration": 6.266229,
     "end_time": "2020-10-26T15:14:10.814651",
     "exception": false,
     "start_time": "2020-10-26T15:14:04.548422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy         5362\n",
      "sadness     4666\n",
      "anger       2159\n",
      "fear        1937\n",
      "love        1304\n",
      "surprise     572\n",
      "Name: 1, dtype: int64\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "[1 1 2 4 2 1 5 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[:,1].value_counts())\n",
    "\n",
    "int_y_train = []\n",
    "int_y_test = []\n",
    "int_y_val = []\n",
    "\n",
    "for l in y_train:\n",
    "    \n",
    "    if l == \"joy\":        \n",
    "        int_y_train.append(0)\n",
    "        \n",
    "    if l == \"sadness\":       \n",
    "        int_y_train.append(1)            \n",
    "    if l == \"anger\":      \n",
    "        int_y_train.append(2)      \n",
    "    if l == \"fear\":\n",
    "        int_y_train.append(3)\n",
    "    if l == \"love\":\n",
    "        int_y_train.append(4)\n",
    "    if l == \"surprise\":\n",
    "        int_y_train.append(5)\n",
    "        \n",
    "        \n",
    "for l in y_test:\n",
    "    \n",
    "    if l == \"joy\":        \n",
    "        int_y_test.append(0)\n",
    "        \n",
    "    if l == \"sadness\":       \n",
    "        int_y_test.append(1)            \n",
    "    if l == \"anger\":      \n",
    "        int_y_test.append(2)      \n",
    "    if l == \"fear\":\n",
    "        int_y_test.append(3)\n",
    "    if l == \"love\":\n",
    "        int_y_test.append(4)\n",
    "    if l == \"surprise\":\n",
    "        int_y_test.append(5)\n",
    "        \n",
    "for l in y_val:\n",
    "    \n",
    "    if l == \"joy\":        \n",
    "        int_y_val.append(0)\n",
    "        \n",
    "    if l == \"sadness\":       \n",
    "        int_y_val.append(1)            \n",
    "    if l == \"anger\":      \n",
    "        int_y_val.append(2)      \n",
    "    if l == \"fear\":\n",
    "        int_y_val.append(3)\n",
    "    if l == \"love\":\n",
    "        int_y_val.append(4)\n",
    "    if l == \"surprise\":\n",
    "        int_y_val.append(5)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "int_y_train,int_y_test,int_y_val = np.array(int_y_train),np.array(int_y_test),np.array(int_y_val)\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(int_y_train)\n",
    "\n",
    "encoded_y_train = le.transform(int_y_train)\n",
    "encoded_y_test = le.transform(int_y_test)\n",
    "encoded_y_val = le.transform(int_y_val)\n",
    "\n",
    "encoded_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "encoded_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "encoded_y_val = np_utils.to_categorical(encoded_y_val)\n",
    "\n",
    "print(encoded_y_train)\n",
    "\n",
    "print(int_y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02645,
     "end_time": "2020-10-26T15:14:10.870291",
     "exception": false,
     "start_time": "2020-10-26T15:14:10.843841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenization\n",
    "\n",
    "In this section I am going to tokenize all the texts and prepare for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:10.926256Z",
     "iopub.status.busy": "2020-10-26T15:14:10.925474Z",
     "iopub.status.idle": "2020-10-26T15:14:10.929075Z",
     "shell.execute_reply": "2020-10-26T15:14:10.929585Z"
    },
    "papermill": {
     "duration": 0.033491,
     "end_time": "2020-10-26T15:14:10.929744",
     "exception": false,
     "start_time": "2020-10-26T15:14:10.896253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i didnt feel humiliated'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:10.989403Z",
     "iopub.status.busy": "2020-10-26T15:14:10.988453Z",
     "iopub.status.idle": "2020-10-26T15:14:10.992206Z",
     "shell.execute_reply": "2020-10-26T15:14:10.992789Z"
    },
    "papermill": {
     "duration": 0.036379,
     "end_time": "2020-10-26T15:14:10.992915",
     "exception": false,
     "start_time": "2020-10-26T15:14:10.956536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im updating my blog because i feel shitty'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:11.049251Z",
     "iopub.status.busy": "2020-10-26T15:14:11.048386Z",
     "iopub.status.idle": "2020-10-26T15:14:11.051879Z",
     "shell.execute_reply": "2020-10-26T15:14:11.052444Z"
    },
    "papermill": {
     "duration": 0.033295,
     "end_time": "2020-10-26T15:14:11.052561",
     "exception": false,
     "start_time": "2020-10-26T15:14:11.019266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im updating my blog because i feel shitty'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025813,
     "end_time": "2020-10-26T15:14:11.104177",
     "exception": false,
     "start_time": "2020-10-26T15:14:11.078364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Our texts looks great, we can tokenize them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:11.171316Z",
     "iopub.status.busy": "2020-10-26T15:14:11.170583Z",
     "iopub.status.idle": "2020-10-26T15:14:13.243211Z",
     "shell.execute_reply": "2020-10-26T15:14:13.243742Z"
    },
    "papermill": {
     "duration": 2.113289,
     "end_time": "2020-10-26T15:14:13.243895",
     "exception": false,
     "start_time": "2020-10-26T15:14:11.130606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feel',\n",
       " 'feeling',\n",
       " 'like',\n",
       " 'im',\n",
       " 'really',\n",
       " 'know',\n",
       " 'time',\n",
       " 'get',\n",
       " 'little',\n",
       " 'people']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "x_train_cl = []\n",
    "x_test_cl = []\n",
    "x_val_cl = []\n",
    "\n",
    "\n",
    "# Deleting stopwords\n",
    "for text in x_train:\n",
    "    \n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    x_train_cl.append(text)\n",
    "    \n",
    "for text in x_test:\n",
    "    \n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    x_test_cl.append(text)\n",
    "\n",
    "for text in x_val:\n",
    "    \n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    x_val_cl.append(text)\n",
    "    \n",
    "x_train,x_test,x_val = np.array(x_train_cl),np.array(x_test_cl),np.array(x_val_cl)\n",
    "\n",
    "# We use total_text for fitting tokenizer in general \n",
    "total_text = np.concatenate((x_train,x_test,x_val),axis=0)\n",
    "\n",
    "num_words = 2000\n",
    "\n",
    "tokenizer = Tokenizer(num_words = num_words) \n",
    "\n",
    "tokenizer.fit_on_texts(total_text)\n",
    "\n",
    "list(tokenizer.word_index)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:13.338572Z",
     "iopub.status.busy": "2020-10-26T15:14:13.323258Z",
     "iopub.status.idle": "2020-10-26T15:14:13.664832Z",
     "shell.execute_reply": "2020-10-26T15:14:13.665287Z"
    },
    "papermill": {
     "duration": 0.395835,
     "end_time": "2020-10-26T15:14:13.665446",
     "exception": false,
     "start_time": "2020-10-26T15:14:13.269611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizing everything\n",
    "\n",
    "x_train_token = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_token = tokenizer.texts_to_sequences(x_test)\n",
    "x_val_token = tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "total_token = np.concatenate((x_train_token,x_test_token,x_val_token),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:13.727484Z",
     "iopub.status.busy": "2020-10-26T15:14:13.726566Z",
     "iopub.status.idle": "2020-10-26T15:14:13.730400Z",
     "shell.execute_reply": "2020-10-26T15:14:13.730973Z"
    },
    "papermill": {
     "duration": 0.040206,
     "end_time": "2020-10-26T15:14:13.731086",
     "exception": false,
     "start_time": "2020-10-26T15:14:13.690880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6699\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "print(np.mean([len(text) for text in total_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024662,
     "end_time": "2020-10-26T15:14:13.780766",
     "exception": false,
     "start_time": "2020-10-26T15:14:13.756104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* We can use 20 as padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:13.839908Z",
     "iopub.status.busy": "2020-10-26T15:14:13.839105Z",
     "iopub.status.idle": "2020-10-26T15:14:13.983017Z",
     "shell.execute_reply": "2020-10-26T15:14:13.982371Z"
    },
    "papermill": {
     "duration": 0.177149,
     "end_time": "2020-10-26T15:14:13.983160",
     "exception": false,
     "start_time": "2020-10-26T15:14:13.806011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  50\n",
      "   1 495]\n",
      "-------------------------------------------------------------------------\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0   30    2\n",
      "  464  425   44   54 1573 1304]\n"
     ]
    }
   ],
   "source": [
    "x_train_pad = pad_sequences(x_train_token,20) \n",
    "x_test_pad = pad_sequences(x_test_token,20)\n",
    "x_val_pad = pad_sequences(x_val_token,20)\n",
    "\n",
    "print(x_train_pad[0],end=\"\\n-------------------------------------------------------------------------\\n\")\n",
    "print(x_train_pad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026367,
     "end_time": "2020-10-26T15:14:14.036770",
     "exception": false,
     "start_time": "2020-10-26T15:14:14.010403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling and Predicting\n",
    "\n",
    "Our data is ready, now lets build a simple RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:14.100021Z",
     "iopub.status.busy": "2020-10-26T15:14:14.099380Z",
     "iopub.status.idle": "2020-10-26T15:14:17.194546Z",
     "shell.execute_reply": "2020-10-26T15:14:17.195142Z"
    },
    "papermill": {
     "duration": 3.130961,
     "end_time": "2020-10-26T15:14:17.195317",
     "exception": false,
     "start_time": "2020-10-26T15:14:14.064356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 100)           200000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 20, 32)            11328     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 16)                2016      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 213,446\n",
      "Trainable params: 213,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,CuDNNGRU,Embedding,Bidirectional\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=2000\n",
    "                   ,output_dim=100\n",
    "                   ,input_length=20))\n",
    "\n",
    "model.add(Bidirectional(CuDNNGRU(units=16,return_sequences=True)))\n",
    "\n",
    "model.add(Bidirectional(CuDNNGRU(units=8)))\n",
    "\n",
    "model.add(Dense(6,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:14:17.256440Z",
     "iopub.status.busy": "2020-10-26T15:14:17.255741Z",
     "iopub.status.idle": "2020-10-26T15:15:38.313602Z",
     "shell.execute_reply": "2020-10-26T15:15:38.314691Z"
    },
    "papermill": {
     "duration": 81.091484,
     "end_time": "2020-10-26T15:15:38.314905",
     "exception": false,
     "start_time": "2020-10-26T15:14:17.223421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 20)\n",
      "(16000,)\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 1.1128 - accuracy: 0.5868\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.3845 - accuracy: 0.8746\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2337 - accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1857 - accuracy: 0.9289\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.1551 - accuracy: 0.9382\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1367 - accuracy: 0.9449\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1248 - accuracy: 0.9504\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1143 - accuracy: 0.9542\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.1064 - accuracy: 0.9584\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0968 - accuracy: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe36051fc50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_pad.shape)\n",
    "print(y_train.shape)\n",
    "model.fit(x_train_pad,encoded_y_train,epochs=10,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:15:39.388428Z",
     "iopub.status.busy": "2020-10-26T15:15:39.387405Z",
     "iopub.status.idle": "2020-10-26T15:15:47.019547Z",
     "shell.execute_reply": "2020-10-26T15:15:47.018899Z"
    },
    "papermill": {
     "duration": 8.140241,
     "end_time": "2020-10-26T15:15:47.019713",
     "exception": false,
     "start_time": "2020-10-26T15:15:38.879472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(x_test_pad)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(preds,int_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.454014,
     "end_time": "2020-10-26T15:15:47.938176",
     "exception": false,
     "start_time": "2020-10-26T15:15:47.484162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.528657,
     "end_time": "2020-10-26T15:15:49.081113",
     "exception": false,
     "start_time": "2020-10-26T15:15:48.552456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now lets take a look at what did I do:\n",
    "\n",
    "1. First I imported the data.\n",
    "1. Then I've prepared labels\n",
    "    * object to int\n",
    "    * int to one hot encode\n",
    "1. Then I've prepared texts\n",
    "    * tokenizing\n",
    "    * padding\n",
    "1. Finally I've build the model.\n",
    "\n",
    "\n",
    "If you like this kernel, please upvote. If you have questions in your mind, I am wating for them. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 111.824016,
   "end_time": "2020-10-26T15:15:51.493061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-26T15:13:59.669045",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
